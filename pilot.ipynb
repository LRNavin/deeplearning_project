{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Vector extraction using Inception V3 pre-trained model\n",
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.core import Activation, Dense, Dropout, Lambda\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from PIL.Image import LANCZOS\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000                                                                                              \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of train images: 103250\n",
      "Amount of train images: 79433\n",
      "Amount of test images: 23818\n",
      "WARNING:tensorflow:From /home/nelssalminen/anaconda3/envs/painter/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv('/home/nelssalminen/painters/data/all_data_info_custom.csv')\n",
    "train_data = pd.read_csv('/home/nelssalminen/painters/data/train_info.csv')\n",
    "test_data = pd.read_csv('/home/nelssalminen/painters/data/test_info.csv')\n",
    "IMG_DIR = '/home/nelssalminen/painters/data/'\n",
    "OUTPUT_DIR = '/home/nelssalminen/painters/data/output/'\n",
    "\n",
    "ALL_IMG_LIST = all_data['new_filename'].tolist()\n",
    "TRAIN_IMG_LIST = train_data['filename'].tolist()\n",
    "TEST_IMG_LIST = test_data['new_filename'].tolist()\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Amount of train images: \" + str(len(ALL_IMG_LIST)))\n",
    "print(\"Amount of train images: \" + str(len(TRAIN_IMG_LIST)))\n",
    "print(\"Amount of test images: \" + str(len(TEST_IMG_LIST)))\n",
    "\n",
    "model = InceptionV3(weights='imagenet',include_top=False,pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#fvec = open(OUTPUT_DIR + 'inceptionv3-vectors.tsv', \"w\")\n",
    "num_vecs = 0 \n",
    "for image_ in IMG_LIST:\n",
    "\timg = image.load_img(IMG_DIR+image_, target_size=(224, 224))\n",
    "\tx = image.img_to_array(img)\n",
    "\tx = np.expand_dims(x, axis=0)\n",
    "\tx = preprocess_input(x)\n",
    "\tfeatures = model.predict(x)[0]\n",
    "\t# Convert from numpy array to a list of values\n",
    "\tfeatures_arr = np.char.mod('%f', features)\n",
    "\n",
    "\tif num_vecs % 100 == 0:\n",
    "\t\tprint(\"{:d} vectors generated\".format(num_vecs))\n",
    "\n",
    "\timage_vector = \",\".join([\"{:.5e}\".format(v) for v in features.tolist()])\n",
    "\tfvec.write(\"{:s}\\t{:s}\\n\".format(image_, image_vector))\n",
    "\tnum_vecs += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Vector classification\n",
    "## Create image triples\n",
    "We start this stage by grouping the images by painter. Once the images are organized, we enumerate through each\n",
    "group of images per artist and randomly obtain a pair of a reference image and a *similar* image. Following this,\n",
    "we randomly select an image from a different artist group, creating a pair of the same reference image, but now combined\n",
    "with a dissimilar image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_img(sid, img_file, img_title):\n",
    "    plt.subplot(sid)\n",
    "    plt.title(img_title)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = imresize(plt.imread(img_file), (512, 512))\n",
    "    plt.imshow(img)\n",
    "\n",
    "def get_triples(image_dir, dat, filename_label='filename', path_prefix=''):\n",
    "        image_groups = {}\n",
    "        for index, row in dat.iterrows():\n",
    "            img_name = row[filename_label]\n",
    "            group_name = row['artist']\n",
    "            if group_name in image_groups:\n",
    "                image_groups[group_name].append(path_prefix + img_name)\n",
    "            else:\n",
    "                image_groups[group_name] = [path_prefix + img_name]\n",
    "\n",
    "        num_sims = 0\n",
    "        image_triples = []\n",
    "        group_list = sorted(list(image_groups.keys()))\n",
    "        for i, g in enumerate(group_list):\n",
    "                if num_sims % 100 == 0:\n",
    "                        print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "                                    .format(num_sims, num_sims, 2*num_sims))\n",
    "                images_in_group = image_groups[g]\n",
    "                sim_pairs_it = itertools.combinations(images_in_group, 2)\n",
    "                # For each similar pair, generate a corresponding different pair\n",
    "                for ref_image, sim_image in sim_pairs_it:\n",
    "                    image_triples.append((ref_image, sim_image, 1))\n",
    "                    num_sims += 1\n",
    "                    while True:\n",
    "                            j = np.random.randint(low=0, high=len(group_list), size=1)[0]\n",
    "                            if j != i:\n",
    "                                    break\n",
    "                    dif_image_candidates = image_groups[group_list[j]]\n",
    "                    k = np.random.randint(low=0, high=len(dif_image_candidates), size=1)[0]\n",
    "                    dif_image = dif_image_candidates[k]\n",
    "                    image_triples.append((ref_image, dif_image, 0))\n",
    "#                     if num_sims % 10000 == 0:\n",
    "#                         show_img(131, os.path.join(IMG_DIR, sim_image), \"sim\")\n",
    "#                         show_img(132, os.path.join(IMG_DIR, ref_image), \"ref\")\n",
    "#                         show_img(133, os.path.join(IMG_DIR, dif_image), \"dif\")\n",
    "#                         plt.tight_layout()\n",
    "#                         plt.show()\n",
    "\n",
    "\n",
    "        print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "                    .format(num_sims, num_sims, 2*num_sims))\n",
    "        return image_triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the image triples using the previously defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 5500 pos + 5500 neg = 11000 total image triples\n",
      "Generated 759100 pos + 759100 neg = 1518200 total image triples\n",
      "Generated 2213600 pos + 2213600 neg = 4427200 total image triples\n",
      "Generated 2740300 pos + 2740300 neg = 5480600 total image triples\n",
      "Generated 2949500 pos + 2949500 neg = 5899000 total image triples\n",
      "Generated 3064500 pos + 3064500 neg = 6129000 total image triples\n",
      "Generated 3755000 pos + 3755000 neg = 7510000 total image triples\n",
      "Generated 4550100 pos + 4550100 neg = 9100200 total image triples\n",
      "Generated 4648400 pos + 4648400 neg = 9296800 total image triples\n",
      "Generated 5435200 pos + 5435200 neg = 10870400 total image triples\n",
      "Generated 5492200 pos + 5492200 neg = 10984400 total image triples\n",
      "Generated 5773652 pos + 5773652 neg = 11547304 total image triples\n",
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 118000 pos + 118000 neg = 236000 total image triples\n",
      "Generated 135400 pos + 135400 neg = 270800 total image triples\n",
      "Generated 179200 pos + 179200 neg = 358400 total image triples\n",
      "Generated 209700 pos + 209700 neg = 419400 total image triples\n",
      "Generated 209700 pos + 209700 neg = 419400 total image triples\n",
      "Generated 292200 pos + 292200 neg = 584400 total image triples\n",
      "Generated 316900 pos + 316900 neg = 633800 total image triples\n",
      "Generated 346400 pos + 346400 neg = 692800 total image triples\n",
      "Generated 511100 pos + 511100 neg = 1022200 total image triples\n",
      "Generated 569270 pos + 569270 neg = 1138540 total image triples\n"
     ]
    }
   ],
   "source": [
    "train_val_triples = get_triples(IMG_DIR, train_data, 'filename', 'train/');\n",
    "test_triples = get_triples(IMG_DIR, test_data, 'new_filename');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/36766.jpg\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_only_images = []\n",
    "for index, row in all_data.iterrows():\n",
    "    image_name = row['new_filename']\n",
    "    artist_group = row['artist_group']\n",
    "    if artist_group == 'test_only':\n",
    "        test_only_images.append(image_name)\n",
    "        \n",
    "sim_pairs_it = itertools.combinations(test_only_images, 2)\n",
    "for ref_image, sim_image in sim_pairs_it:\n",
    "    image_triples.append((ref_image, sim_image, 1))\n",
    "    num_sims += 1\n",
    "    while True:\n",
    "            j = np.random.randint(low=0, high=len(group_list), size=1)[0]\n",
    "            if j != i:\n",
    "                    break\n",
    "    dif_image_candidates = image_groups[group_list[j]]\n",
    "    k = np.random.randint(low=0, high=len(dif_image_candidates), size=1)[0]\n",
    "    dif_image = dif_image_candidates[k]\n",
    "    image_triples.append((ref_image, dif_image, 0))\n",
    "\n",
    "print(len(sim_pairs_it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set several configuration and utility variables, including loading the vector files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_vectors(vector_file, prefix_filter=''):\n",
    "        vec_dict = {}\n",
    "        fvec = open(vector_file, \"r\")\n",
    "        for line in fvec:\n",
    "                image_name, image_vec = line.strip().split(\"\\t\")\n",
    "                #if prefix_filter != '' and image_name.startswith(prefix_filter):\n",
    "                vec = np.array([float(v) for v in image_vec.split(\",\")])\n",
    "                vec_dict[image_name] = vec\n",
    "        fvec.close()\n",
    "        return vec_dict\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 35\n",
    "\n",
    "DATA_CONTAINER = '/home/nelssalminen/painters/data/scratch/'\n",
    "os.makedirs(DATA_CONTAINER, exist_ok=True)\n",
    "\n",
    "VECTORIZERS = [\"InceptionV3\"]\n",
    "MERGE_MODES = [\"Concat\", \"Euclidean\"]\n",
    "\n",
    "scores = np.zeros((len(VECTORIZERS), len(MERGE_MODES)))\n",
    "\n",
    "VECTOR_SIZE = 2048\n",
    "VECTOR_FILE = os.path.join(OUTPUT_DIR, \"inceptionv3-vectors_alldata.tsv\")\n",
    "\n",
    "vec_dict = load_vectors(VECTOR_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103250\n"
     ]
    }
   ],
   "source": [
    "print(len(vec_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the triples for training, validation and testing based on given ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 10392573 Validation set size:1154731 Test set size:1138540\n"
     ]
    }
   ],
   "source": [
    "def train_val_split(triples, splits):\n",
    "        assert sum(splits) == 1.0\n",
    "        split_pts = np.cumsum(np.array([0.] + splits))\n",
    "        indices = np.random.permutation(np.arange(len(triples)))\n",
    "        shuffled_triples = [triples[i] for i in indices]\n",
    "        data_splits = []\n",
    "        for sid in range(len(splits)):\n",
    "                start = int(split_pts[sid] * len(triples))\n",
    "                end = int(split_pts[sid + 1] * len(triples))\n",
    "                data_splits.append(shuffled_triples[start:end])\n",
    "        return data_splits\n",
    "\n",
    "train_triples, val_triples = train_val_split(train_val_triples, splits=[0.9, 0.1])\n",
    "print(\"Training set size: \" + str(len(train_triples)), \"Validation set size:\" + str(len(val_triples)), \"Test set size:\" + str(len(test_triples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def batch_to_vectors(batch, vec_size, vec_dict):\n",
    "    X1 = np.zeros((len(batch), vec_size))\n",
    "    X2 = np.zeros((len(batch), vec_size))\n",
    "    Y = np.zeros((len(batch), 2))\n",
    "    for tid in range(len(batch)):\n",
    "        X1[tid] = vec_dict[batch[tid][0]]\n",
    "        X2[tid] = vec_dict[batch[tid][1]]\n",
    "        Y[tid] = [1, 0] if batch[tid][2] == 0 else [0, 1]\n",
    "    return ([X1, X2], Y)\n",
    "\n",
    "\n",
    "def data_generator(triples, vec_size, vec_dict, batch_size=32):\n",
    "    while True:\n",
    "        # shuffle once per batch\n",
    "        indices = np.random.permutation(np.arange(len(triples)))\n",
    "        num_batches = len(triples) // batch_size\n",
    "        for bid in range(num_batches):\n",
    "            batch_indices = indices[bid * batch_size: (bid + 1) * batch_size]\n",
    "            batch = [triples[i] for i in batch_indices]\n",
    "            yield batch_to_vectors(batch, vec_size, vec_dict)\n",
    "            \n",
    "train_gen = data_generator(train_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(VECTOR_SIZE,))\n",
    "input_2 = Input(shape=(VECTOR_SIZE,))\n",
    "merged = Concatenate(axis=-1)([input_1, input_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the 10-layer Siamese CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 4096)         0           input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 2048)         8390656     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 2048)         0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 2048)         0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 2048)         4196352     activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 2048)         0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 2048)         0           dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 2048)         4196352     activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 2048)         0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 2048)         0           dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1024)         2098176     activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 1024)         0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 1024)         0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1024)         1049600     activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 1024)         0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 1024)         0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1024)         1049600     activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1024)         0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 1024)         0           dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 512)          524800      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 512)          0           dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 512)          0           dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 512)          262656      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 512)          0           dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 512)          0           dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 128)          65664       activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 128)          0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 128)          0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 128)          16512       activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 128)          0           dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 128)          0           dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 2)            258         activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 2)            0           dense_33[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,850,626\n",
      "Trainable params: 21,850,626\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc1 = Dense(2048, kernel_initializer=\"glorot_uniform\")(merged)\n",
    "fc1 = Dropout(0.2)(fc1)\n",
    "fc1 = Activation(\"relu\")(fc1)\n",
    "\n",
    "fc2 = Dense(2048, kernel_initializer=\"glorot_uniform\")(fc1)\n",
    "fc2 = Dropout(0.2)(fc2)\n",
    "fc2 = Activation(\"relu\")(fc2)\n",
    "\n",
    "fc3 = Dense(2048, kernel_initializer=\"glorot_uniform\")(fc2)\n",
    "fc3 = Dropout(0.2)(fc3)\n",
    "fc3 = Activation(\"relu\")(fc3)\n",
    "\n",
    "fc8 = Dense(1024, kernel_initializer=\"glorot_uniform\")(fc3)\n",
    "fc8 = Dropout(0.2)(fc8)\n",
    "fc8 = Activation(\"relu\")(fc8)\n",
    "\n",
    "fc9 = Dense(1024, kernel_initializer=\"glorot_uniform\")(fc8)\n",
    "fc9 = Dropout(0.2)(fc9)\n",
    "fc9 = Activation(\"relu\")(fc9)\n",
    "\n",
    "fc11 = Dense(1024, kernel_initializer=\"glorot_uniform\")(fc9)\n",
    "fc11 = Dropout(0.2)(fc11)\n",
    "fc11 = Activation(\"relu\")(fc11)\n",
    "\n",
    "fc12 = Dense(512, kernel_initializer=\"glorot_uniform\")(fc11)\n",
    "fc12 = Dropout(0.2)(fc12)\n",
    "fc12 = Activation(\"relu\")(fc12)\n",
    "\n",
    "fc13 = Dense(512, kernel_initializer=\"glorot_uniform\")(fc12)\n",
    "fc13 = Dropout(0.2)(fc13)\n",
    "fc13 = Activation(\"relu\")(fc13)\n",
    "\n",
    "fc14 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc13)\n",
    "fc14 = Dropout(0.2)(fc14)\n",
    "fc14 = Activation(\"relu\")(fc14)\n",
    "\n",
    "fc15 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc14)\n",
    "fc15 = Dropout(0.2)(fc15)\n",
    "fc15 = Activation(\"relu\")(fc15)\n",
    "\n",
    "pred = Dense(2, kernel_initializer=\"glorot_uniform\")(fc15)\n",
    "pred = Activation(\"softmax\")(pred)\n",
    "\n",
    "model = Model(inputs=[input_1, input_2], outputs=pred)\n",
    "adam = Adam(lr=.00001)\n",
    "model.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_file, test_gen):\n",
    "        model_name = os.path.basename(model_file)\n",
    "        model = load_model(model_file)\n",
    "        print(\"=== Evaluating model: {:s} ===\".format(model_name))\n",
    "        ytrue, ypred = [], []\n",
    "        num_test_steps = len(test_triples) // BATCH_SIZE\n",
    "        for i in range(num_test_steps):\n",
    "                (X1, X2), Y = next(test_gen)\n",
    "                Y_ = model.predict([X1, X2])\n",
    "                ytrue.extend(np.argmax(Y, axis=1).tolist())\n",
    "                ypred.extend(np.argmax(Y_, axis=1).tolist())\n",
    "        accuracy = accuracy_score(ytrue, ypred)\n",
    "        print(\"\\nAccuracy: {:.3f}\".format(accuracy))\n",
    "        print(\"\\nConfusion Matrix\")\n",
    "        print(confusion_matrix(ytrue, ypred))\n",
    "        print(\"\\nClassification Report\")\n",
    "        print(classification_report(ytrue, ypred))\n",
    "        return accuracy\n",
    "    \n",
    "def get_model_file(data_dir, vector_name, merge_mode, borf):\n",
    "        return os.path.join(data_dir, \"models\", \"{:s}-{:s}-{:s}.h5\"\n",
    "                                                .format(vector_name, merge_mode, borf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "40595/40595 [==============================] - 827s 20ms/step - loss: 0.6289 - acc: 0.6339 - val_loss: 0.5722 - val_acc: 0.7055\n",
      "Epoch 2/35\n",
      "40595/40595 [==============================] - 815s 20ms/step - loss: 0.5343 - acc: 0.7241 - val_loss: 0.5034 - val_acc: 0.7678\n",
      "Epoch 3/35\n",
      "40595/40595 [==============================] - 813s 20ms/step - loss: 0.4704 - acc: 0.7711 - val_loss: 0.4453 - val_acc: 0.8040\n",
      "Epoch 4/35\n",
      "40595/40595 [==============================] - 815s 20ms/step - loss: 0.4247 - acc: 0.8019 - val_loss: 0.4094 - val_acc: 0.8286\n",
      "Epoch 5/35\n",
      "40595/40595 [==============================] - 813s 20ms/step - loss: 0.3916 - acc: 0.8231 - val_loss: 0.3782 - val_acc: 0.8439\n",
      "Epoch 6/35\n",
      "40595/40595 [==============================] - 812s 20ms/step - loss: 0.3665 - acc: 0.8383 - val_loss: 0.3698 - val_acc: 0.8549\n",
      "Epoch 7/35\n",
      "40595/40595 [==============================] - 815s 20ms/step - loss: 0.3470 - acc: 0.8496 - val_loss: 0.3503 - val_acc: 0.8643\n",
      "Epoch 8/35\n",
      "40595/40595 [==============================] - 811s 20ms/step - loss: 0.3315 - acc: 0.8585 - val_loss: 0.3369 - val_acc: 0.8701\n",
      "Epoch 9/35\n",
      "40595/40595 [==============================] - 810s 20ms/step - loss: 0.3190 - acc: 0.8653 - val_loss: 0.3265 - val_acc: 0.8750\n",
      "Epoch 10/35\n",
      "40595/40595 [==============================] - 810s 20ms/step - loss: 0.3085 - acc: 0.8709 - val_loss: 0.3177 - val_acc: 0.8778\n",
      "Epoch 11/35\n",
      "40595/40595 [==============================] - 809s 20ms/step - loss: 0.2995 - acc: 0.8755 - val_loss: 0.3137 - val_acc: 0.8817\n",
      "Epoch 12/35\n",
      "40595/40595 [==============================] - 810s 20ms/step - loss: 0.2917 - acc: 0.8795 - val_loss: 0.3084 - val_acc: 0.8844\n",
      "Epoch 13/35\n",
      "40595/40595 [==============================] - 810s 20ms/step - loss: 0.2849 - acc: 0.8828 - val_loss: 0.3018 - val_acc: 0.8860\n",
      "Epoch 14/35\n",
      "40595/40595 [==============================] - 808s 20ms/step - loss: 0.2787 - acc: 0.8858 - val_loss: 0.2941 - val_acc: 0.8882\n",
      "Epoch 15/35\n",
      "40595/40595 [==============================] - 808s 20ms/step - loss: 0.2732 - acc: 0.8885 - val_loss: 0.2968 - val_acc: 0.8880\n",
      "Epoch 16/35\n",
      "40595/40595 [==============================] - 808s 20ms/step - loss: 0.2679 - acc: 0.8910 - val_loss: 0.2916 - val_acc: 0.8919\n",
      "Epoch 17/35\n",
      "40595/40595 [==============================] - 808s 20ms/step - loss: 0.2632 - acc: 0.8933 - val_loss: 0.2868 - val_acc: 0.8921\n",
      "Epoch 18/35\n",
      "40595/40595 [==============================] - 809s 20ms/step - loss: 0.2586 - acc: 0.8954 - val_loss: 0.2871 - val_acc: 0.8932\n",
      "Epoch 19/35\n",
      "40595/40595 [==============================] - 807s 20ms/step - loss: 0.2544 - acc: 0.8974 - val_loss: 0.2754 - val_acc: 0.8954\n",
      "Epoch 20/35\n",
      "40595/40595 [==============================] - 808s 20ms/step - loss: 0.2503 - acc: 0.8993 - val_loss: 0.2788 - val_acc: 0.8964\n",
      "Epoch 21/35\n",
      "40595/40595 [==============================] - 807s 20ms/step - loss: 0.2466 - acc: 0.9008 - val_loss: 0.2793 - val_acc: 0.8950\n",
      "Epoch 22/35\n",
      "40595/40595 [==============================] - 808s 20ms/step - loss: 0.2431 - acc: 0.9025 - val_loss: 0.2746 - val_acc: 0.8965\n",
      "Epoch 23/35\n",
      "40595/40595 [==============================] - 810s 20ms/step - loss: 0.2397 - acc: 0.9041 - val_loss: 0.2696 - val_acc: 0.8995\n",
      "Epoch 24/35\n",
      "40595/40595 [==============================] - 807s 20ms/step - loss: 0.2367 - acc: 0.9055 - val_loss: 0.2687 - val_acc: 0.8996\n",
      "Epoch 25/35\n",
      "40595/40595 [==============================] - 808s 20ms/step - loss: 0.2336 - acc: 0.9068 - val_loss: 0.2653 - val_acc: 0.9015\n",
      "Epoch 26/35\n",
      "40595/40595 [==============================] - 808s 20ms/step - loss: 0.2308 - acc: 0.9080 - val_loss: 0.2610 - val_acc: 0.9018\n",
      "Epoch 27/35\n",
      "40595/40595 [==============================] - 809s 20ms/step - loss: 0.2280 - acc: 0.9093 - val_loss: 0.2588 - val_acc: 0.9028\n",
      "Epoch 28/35\n",
      "40595/40595 [==============================] - 815s 20ms/step - loss: 0.2256 - acc: 0.9104 - val_loss: 0.2546 - val_acc: 0.9030\n",
      "Epoch 29/35\n",
      "40595/40595 [==============================] - 820s 20ms/step - loss: 0.2229 - acc: 0.9116 - val_loss: 0.2554 - val_acc: 0.9039\n",
      "Epoch 30/35\n",
      "40595/40595 [==============================] - 824s 20ms/step - loss: 0.2212 - acc: 0.9124 - val_loss: 0.2592 - val_acc: 0.9031\n",
      "Epoch 31/35\n",
      "40595/40595 [==============================] - 819s 20ms/step - loss: 0.2188 - acc: 0.9134 - val_loss: 0.2540 - val_acc: 0.9046\n",
      "Epoch 32/35\n",
      "40595/40595 [==============================] - 811s 20ms/step - loss: 0.2165 - acc: 0.9144 - val_loss: 0.2494 - val_acc: 0.9059\n",
      "Epoch 33/35\n",
      "40595/40595 [==============================] - 811s 20ms/step - loss: 0.2142 - acc: 0.9155 - val_loss: 0.2478 - val_acc: 0.9064\n",
      "Epoch 34/35\n",
      "40595/40595 [==============================] - 810s 20ms/step - loss: 0.2128 - acc: 0.9163 - val_loss: 0.2492 - val_acc: 0.9066\n",
      "Epoch 35/35\n",
      "40595/40595 [==============================] - 819s 20ms/step - loss: 0.2109 - acc: 0.9168 - val_loss: 0.2485 - val_acc: 0.9066\n",
      "=== Evaluating model: inceptionv3r2-cat-final.h5 ===\n",
      "\n",
      "Accuracy: 0.617\n",
      "\n",
      "Confusion Matrix\n",
      "[[355732 213494]\n",
      " [222201 347005]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62    569226\n",
      "           1       0.62      0.61      0.61    569206\n",
      "\n",
      "   micro avg       0.62      0.62      0.62   1138432\n",
      "   macro avg       0.62      0.62      0.62   1138432\n",
      "weighted avg       0.62      0.62      0.62   1138432\n",
      "\n",
      "=== Evaluating model: inceptionv3r2-cat-best.h5 ===\n",
      "\n",
      "Accuracy: 0.612\n",
      "\n",
      "Confusion Matrix\n",
      "[[371466 197754]\n",
      " [243692 325520]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.63    569220\n",
      "           1       0.62      0.57      0.60    569212\n",
      "\n",
      "   micro avg       0.61      0.61      0.61   1138432\n",
      "   macro avg       0.61      0.61      0.61   1138432\n",
      "weighted avg       0.61      0.61      0.61   1138432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_name = get_model_file(DATA_CONTAINER, \"inceptionv3r2\", \"cat\", \"best\")\n",
    "checkpoint = ModelCheckpoint(best_model_name, save_best_only=True)\n",
    "train_steps_per_epoch = len(train_triples) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(val_triples) // BATCH_SIZE\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps_per_epoch, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              validation_data=val_gen, validation_steps=val_steps_per_epoch,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "final_model_name = get_model_file(DATA_CONTAINER, \"inceptionv3r2\", \"cat\", \"final\")\n",
    "model.save(final_model_name)\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "final_accuracy = evaluate_model(final_model_name, test_gen)\n",
    "\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "best_accuracy = evaluate_model(best_model_name, test_gen)\n",
    "\n",
    "scores[0, 0] = best_accuracy if best_accuracy > final_accuracy else final_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
