{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Vector extraction using Inception V3 pre-trained model\n",
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.core import Activation, Dense, Dropout, Lambda\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from PIL.Image import LANCZOS\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000                                                                                              \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79433\n",
      "WARNING:tensorflow:From /home/nelssalminen/anaconda3/envs/painter/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv('/home/nelssalminen/painters/data/train_info.csv')\n",
    "IMG_LIST = dat['filename'].tolist()\n",
    "IMG_DIR = '/home/nelssalminen/painters/data/train/'\n",
    "OUTPUT_DIR = '/home/nelssalminen/painters/data/output/'\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(len(IMG_LIST))\n",
    "\n",
    "model = InceptionV3(weights='imagenet',include_top=False,pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#fvec = open(OUTPUT_DIR + 'inceptionv3-vectors.tsv', \"w\")\n",
    "num_vecs = 0 \n",
    "for image_ in IMG_LIST:\n",
    "\timg = image.load_img(IMG_DIR+image_, target_size=(224, 224))\n",
    "\tx = image.img_to_array(img)\n",
    "\tx = np.expand_dims(x, axis=0)\n",
    "\tx = preprocess_input(x)\n",
    "\tfeatures = model.predict(x)[0]\n",
    "\t# Convert from numpy array to a list of values\n",
    "\tfeatures_arr = np.char.mod('%f', features)\n",
    "\n",
    "\tif num_vecs % 100 == 0:\n",
    "\t\tprint(\"{:d} vectors generated\".format(num_vecs))\n",
    "\n",
    "\timage_vector = \",\".join([\"{:.5e}\".format(v) for v in features.tolist()])\n",
    "\tfvec.write(\"{:s}\\t{:s}\\n\".format(image_, image_vector))\n",
    "\tnum_vecs += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Vector classification\n",
    "## Create image triples\n",
    "We start this stage by grouping the images by painter. Once the images are organized, we enumerate through each\n",
    "group of images per artist and randomly obtain a pair of a reference image and a *similar* image. Following this,\n",
    "we randomly select an image from a different artist group, creating a pair of the same reference image, but now combined\n",
    "with a dissimilar image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5ccd38b260edb40fc788b86761475dc3', '78e52c4888ac7356d3f9330c7f6d8efa', 'f241a8a2df78010687adc1b433248db2', '4f5f7ea6bfde0b20405cf17c3d080e8d', '24737e13e24bf959b89f88d35aae6f18', 'bf3d528ccc483dbae4421d5d4486dcf4', '4928068b969eb94d712513fb37775b69', '4bd6166a198cb687545a6e62f735458f', 'a921bba6adb1ef505aaaf2f7d993259c', 'b63534983e7d5389c3eb238a99a01f1f', '65972a3cdf808987b805b2f77b84f767', '58d8e97010e5340295564f9b26a91c9e', '5c4a0fe7dd40c408a6d094cb117b2ddf', 'c8792a07d9c3e3aaa94cf7c0b3bce17d', 'b3c8aac6b09a9462f18eaddcc8d8c8b6', '25b752932874a46bf760fbb4ba3ae154', 'a5f516b48d9be09d865a17e28f578664', 'c4a9bd575234cb4fd3ac9bb465801133', '7df32a5921612479ead3053cc3fef603', 'cc855b3d3c291ffba43e07934e8fb616', '59f6f564b33837275aebc04294fb23b9', 'f5a190b5e7c20a137c614799eebe9479', '6da85288541891498dd65e07d3b64371', '464fee66276dfef8e065a8d60d2e8b42', '6ec94ae04aa9443ab71f504e5e5af607', '5d9e88804f8a905749ce7ca7a86301df', 'fc1f3b2cf51749fec8a6496e02e26673', '79c5b2fac57715daff80d6ca923de6f7', '9fda1854e1e5984b2262a6b2db7560fa', '10be6a2b5f23ad60bbea05bb2b9fe392', '8ef0bc70e38abdb1e74e52a27a6a9140', '1ef451a39c6209ccfd746b165e077204', 'df20d38749b15b4b50d5698b0c5ff8d9', '8b1ccac989298828362850b15b50ef8b', 'ec93fb2e5715a94510661c43ea9f2c92', '50c1b468d1dd2d3043b2348fe5d80114', 'fcd86617eb1b590ff64b9d49b518e915', 'c1757052ba73cd1b6347165882ec659f', '2ec05210b67f6af847e020d1fede26d4', 'c720a4e60828ae0c64bf25e3a7a423ee', 'bb056543e5f08eceef4a1bc37946d336', '2277ceef9e06b0a841062fdfa6de971d', '77841bd89ee70bdb16c4a7297a734ff2', '4b0187fdb20ce2065f12515070928007', '75002938e36a22673330e79f4a751767', '862bd4deed815bd431e5c2ac84ff0953', '4329eecc5a023ee3a9065e70111800a1', '00f78fa862830cc1ba569285da3232ed', '093d54c8398df0ab85b48e53faa54940', '09e1122dcc7247509bf3a7232268cab7', '2766e4c8b73e0cb18f793451e26ffafb', '587e77e004566975b01f264469cc19b1', '0dcfecf6e6a3ac3ec200de01e5f7f8f7', '3007fcba96d9941a481321b6367721a1', '37c963182bf5c9a5bf9504bb18d2a669', '2574d646c4252bdd87d253847eedfdf3', 'f26d55e95372a879c9ec4f7a91e19076', '539e995db6d621c00835cb6218489d8d', '294d0a61d897faf13708824d9a86bb04', 'ad7236b81e5471a18f7a7b8a2201ea88', '76c03c40b46da53c2e1fdd431b32c9fa', '5aa46c4bd5cd785c39b45c221984838e', '6be4b4c5a63d2508f0fc06d7dd8ad391', 'bbeaac68870859dddc0fc669cbd7734c', 'dd7059dda72e295b8f213dc15bf2ccb7', 'bf4915402893875e357cc537fd89dd9f', '07c533c28369f1e2b027f6a0c827d90e', 'f258cbc24958b6fd973e711ca4f19354', '7947c26080059d75a1230803dd4307b5', '513530a8e473ab2f1d89fcf3684829d4', 'd357a7e5853194fbd6262a1a8c21bc3f', '2f5a90d2491aeddfeff7230bf4119f08', '4f2a6e08d4919a4b7275d9ce6be6fbe3', '0d899a0eb3988f433ffc667b55bd430e', '8b9d3c0614c9f0f0ac004a4e59872862', '003cb9bdfadc23495b51a630f8af2570', '3267c7910e67fdca840d4c38f72e4b70', '0c4aebb696abe69e8b437abba61f6084', '2a2f5222c870a3843794188fdfb9a85a', '139e4feb4346b2ef87afb7be838e8220']\n"
     ]
    }
   ],
   "source": [
    "def get_bottom_x_images(x):\n",
    "    #create dictionary of all artists and paintings\n",
    "    image_groups = {}\n",
    "    for index, row in dat.iterrows():\n",
    "        img_name = row['filename']\n",
    "        group_name = row['artist']\n",
    "        if group_name in image_groups:\n",
    "            image_groups[group_name].append(img_name)\n",
    "        else:\n",
    "            image_groups[group_name] = [img_name]\n",
    "    \n",
    "    csv_top = []\n",
    "    \n",
    "    #create an arracy of artists and the number of paintings they've drawn\n",
    "    for i in image_groups:\n",
    "       csv_top.append((i,len(image_groups[i])))\n",
    "    #sort the above array by ranking of number of paintings\n",
    "    csv_top = sorted(csv_top,key=lambda l:l[1], reverse=True)\n",
    "    \n",
    "    #define csv_top as list of bottom x artists\n",
    "    csv_top = csv_top[-x:]\n",
    "        \n",
    "    top_image_groups = {}\n",
    "    for i in csv_top:\n",
    "        top_artist = i[0]\n",
    "        for artist, image in image_groups.items():\n",
    "            if top_artist == artist:\n",
    "                top_image_groups[artist] = image\n",
    "    return top_image_groups\n",
    "\n",
    "list_image = get_bottom_x_images(80)\n",
    "excluded_artists = list(list_image.keys())\n",
    "print(excluded_artists)\n",
    "excluded_images = [item for sublist in list_image.values() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_img(sid, img_file, img_title):\n",
    "    plt.subplot(sid)\n",
    "    plt.title(img_title)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = imresize(plt.imread(img_file), (512, 512))\n",
    "    plt.imshow(img)\n",
    "\n",
    "def get_triples(image_dir):\n",
    "        image_groups = {}\n",
    "        for index, row in dat.iterrows():\n",
    "            img_name = row['filename']\n",
    "            group_name = row['artist']\n",
    "            if group_name not in excluded_artists:\n",
    "                if group_name in image_groups:\n",
    "                    image_groups[group_name].append(img_name)\n",
    "                else:\n",
    "                    image_groups[group_name] = [img_name]\n",
    "\n",
    "        num_sims = 0\n",
    "        image_triples = []\n",
    "        group_list = sorted(list(image_groups.keys()))\n",
    "        for i, g in enumerate(group_list):\n",
    "                if g in excluded_artists:\n",
    "                    print(\"Wait a minute here... hmmmm\")\n",
    "                if num_sims % 100 == 0:\n",
    "                        print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "                                    .format(num_sims, num_sims, 2*num_sims))\n",
    "                images_in_group = image_groups[g]\n",
    "                sim_pairs_it = itertools.combinations(images_in_group, 2)\n",
    "                # For each similar pair, generate a corresponding different pair\n",
    "                for ref_image, sim_image in sim_pairs_it:\n",
    "                    image_triples.append((ref_image, sim_image, 1))\n",
    "                    num_sims += 1\n",
    "                    while True:\n",
    "                            j = np.random.randint(low=0, high=len(group_list), size=1)[0]\n",
    "                            if j != i:\n",
    "                                    break\n",
    "                    dif_image_candidates = image_groups[group_list[j]]\n",
    "                    k = np.random.randint(low=0, high=len(dif_image_candidates), size=1)[0]\n",
    "                    dif_image = dif_image_candidates[k]\n",
    "                    image_triples.append((ref_image, dif_image, 0))\n",
    "#                     if num_sims % 10000 == 0:\n",
    "#                         show_img(131, os.path.join(IMG_DIR, sim_image), \"sim\")\n",
    "#                         show_img(132, os.path.join(IMG_DIR, ref_image), \"ref\")\n",
    "#                         show_img(133, os.path.join(IMG_DIR, dif_image), \"dif\")\n",
    "#                         plt.tight_layout()\n",
    "#                         plt.show()\n",
    "\n",
    "\n",
    "        print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "                    .format(num_sims, num_sims, 2*num_sims))\n",
    "        return image_triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the image triples using the previously defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 873100 pos + 873100 neg = 1746200 total image triples\n",
      "Generated 987100 pos + 987100 neg = 1974200 total image triples\n",
      "Generated 2472900 pos + 2472900 neg = 4945800 total image triples\n",
      "Generated 3064200 pos + 3064200 neg = 6128400 total image triples\n",
      "Generated 3102000 pos + 3102000 neg = 6204000 total image triples\n",
      "Generated 3753800 pos + 3753800 neg = 7507600 total image triples\n",
      "Generated 5361500 pos + 5361500 neg = 10723000 total image triples\n",
      "Generated 5766400 pos + 5766400 neg = 11532800 total image triples\n",
      "Generated 5772145 pos + 5772145 neg = 11544290 total image triples\n"
     ]
    }
   ],
   "source": [
    "triples = get_triples(IMG_DIR);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set several configuration and utility variables, including loading the vector files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_vectors(vector_file, excl):\n",
    "        vec_dict = {}\n",
    "        fvec = open(vector_file, \"r\")\n",
    "        for line in fvec:\n",
    "                image_name, image_vec = line.strip().split(\"\\t\")\n",
    "                if image_name not in excl:\n",
    "                    vec = np.array([float(v) for v in image_vec.split(\",\")])\n",
    "                    vec_dict[image_name] = vec\n",
    "        fvec.close()\n",
    "        return vec_dict\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 35\n",
    "\n",
    "DATA_CONTAINER = '/home/nelssalminen/painters/data/scratch/'\n",
    "os.makedirs(DATA_CONTAINER, exist_ok=True)\n",
    "\n",
    "VECTORIZERS = [\"InceptionV3\"]\n",
    "MERGE_MODES = [\"Concat\", \"Euclidean\"]\n",
    "\n",
    "scores = np.zeros((len(VECTORIZERS), len(MERGE_MODES)))\n",
    "\n",
    "VECTOR_SIZE = 2048\n",
    "VECTOR_FILE = os.path.join(OUTPUT_DIR, \"inceptionv3-vectors.tsv\")\n",
    "\n",
    "vec_dict = load_vectors(VECTOR_FILE, excluded_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the triples for training, validation and testing based on given ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 9235432 Validation set size:1154429 Test set size:1154429\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(triples, splits):\n",
    "        assert sum(splits) == 1.0\n",
    "        split_pts = np.cumsum(np.array([0.] + splits))\n",
    "        indices = np.random.permutation(np.arange(len(triples)))\n",
    "        shuffled_triples = [triples[i] for i in indices]\n",
    "        data_splits = []\n",
    "        for sid in range(len(splits)):\n",
    "                start = int(split_pts[sid] * len(triples))\n",
    "                end = int(split_pts[sid + 1] * len(triples))\n",
    "                data_splits.append(shuffled_triples[start:end])\n",
    "        return data_splits\n",
    "\n",
    "train_triples, val_triples, test_triples = train_test_split(triples, splits=[0.8, 0.1, 0.1])\n",
    "print(\"Training set size: \" + str(len(train_triples)), \"Validation set size:\" + str(len(val_triples)), \"Test set size:\" + str(len(test_triples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Add explanation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def batch_to_vectors(batch, vec_size, vec_dict):\n",
    "    X1 = np.zeros((len(batch), vec_size))\n",
    "    X2 = np.zeros((len(batch), vec_size))\n",
    "    Y = np.zeros((len(batch), 2))\n",
    "    for tid in range(len(batch)):\n",
    "        X1[tid] = vec_dict[batch[tid][0]]\n",
    "        X2[tid] = vec_dict[batch[tid][1]]\n",
    "        Y[tid] = [1, 0] if batch[tid][2] == 0 else [0, 1]\n",
    "    return ([X1, X2], Y)\n",
    "\n",
    "\n",
    "def data_generator(triples, vec_size, vec_dict, batch_size=32):\n",
    "    while True:\n",
    "        # shuffle once per batch\n",
    "        indices = np.random.permutation(np.arange(len(triples)))\n",
    "        num_batches = len(triples) // batch_size\n",
    "        for bid in range(num_batches):\n",
    "            batch_indices = indices[bid * batch_size: (bid + 1) * batch_size]\n",
    "            batch = [triples[i] for i in batch_indices]\n",
    "            yield batch_to_vectors(batch, vec_size, vec_dict)\n",
    "            \n",
    "train_gen = data_generator(train_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(VECTOR_SIZE,))\n",
    "input_2 = Input(shape=(VECTOR_SIZE,))\n",
    "merged = Concatenate(axis=-1)([input_1, input_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the 10-layer Siamese CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nelssalminen/anaconda3/envs/painter/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4096)         0           input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         8390656     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 2048)         0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2048)         4196352     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 2048)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2048)         4196352     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2048)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 2048)         0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         2098176     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 1024)         0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         1049600     activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 1024)         0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         1049600     activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 1024)         0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          524800      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 512)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 512)          0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          262656      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 512)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 512)          0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          65664       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 128)          0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          16512       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 128)          0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            258         activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 2)            0           dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,850,626\n",
      "Trainable params: 21,850,626\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc1 = Dense(2048, kernel_initializer=\"glorot_uniform\")(merged)\n",
    "fc1 = Dropout(0.2)(fc1)\n",
    "fc1 = Activation(\"relu\")(fc1)\n",
    "\n",
    "fc2 = Dense(2048, kernel_initializer=\"glorot_uniform\")(fc1)\n",
    "fc2 = Dropout(0.2)(fc2)\n",
    "fc2 = Activation(\"relu\")(fc2)\n",
    "\n",
    "fc3 = Dense(2048, kernel_initializer=\"glorot_uniform\")(fc2)\n",
    "fc3 = Dropout(0.2)(fc3)\n",
    "fc3 = Activation(\"relu\")(fc3)\n",
    "\n",
    "fc8 = Dense(1024, kernel_initializer=\"glorot_uniform\")(fc3)\n",
    "fc8 = Dropout(0.2)(fc8)\n",
    "fc8 = Activation(\"relu\")(fc8)\n",
    "\n",
    "fc9 = Dense(1024, kernel_initializer=\"glorot_uniform\")(fc8)\n",
    "fc9 = Dropout(0.2)(fc9)\n",
    "fc9 = Activation(\"relu\")(fc9)\n",
    "\n",
    "fc11 = Dense(1024, kernel_initializer=\"glorot_uniform\")(fc9)\n",
    "fc11 = Dropout(0.2)(fc11)\n",
    "fc11 = Activation(\"relu\")(fc11)\n",
    "\n",
    "fc12 = Dense(512, kernel_initializer=\"glorot_uniform\")(fc11)\n",
    "fc12 = Dropout(0.2)(fc12)\n",
    "fc12 = Activation(\"relu\")(fc12)\n",
    "\n",
    "fc13 = Dense(512, kernel_initializer=\"glorot_uniform\")(fc12)\n",
    "fc13 = Dropout(0.2)(fc13)\n",
    "fc13 = Activation(\"relu\")(fc13)\n",
    "\n",
    "fc14 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc13)\n",
    "fc14 = Dropout(0.2)(fc14)\n",
    "fc14 = Activation(\"relu\")(fc14)\n",
    "\n",
    "fc15 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc14)\n",
    "fc15 = Dropout(0.2)(fc15)\n",
    "fc15 = Activation(\"relu\")(fc15)\n",
    "\n",
    "pred = Dense(2, kernel_initializer=\"glorot_uniform\")(fc15)\n",
    "pred = Activation(\"softmax\")(pred)\n",
    "\n",
    "model = Model(inputs=[input_1, input_2], outputs=pred)\n",
    "adam = Adam(lr=.00001)\n",
    "model.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_file, test_gen):\n",
    "        model_name = os.path.basename(model_file)\n",
    "        model = load_model(model_file)\n",
    "        print(\"=== Evaluating model: {:s} ===\".format(model_name))\n",
    "        ytrue, ypred = [], []\n",
    "        num_test_steps = len(test_triples) // BATCH_SIZE\n",
    "        for i in range(num_test_steps):\n",
    "                (X1, X2), Y = next(test_gen)\n",
    "                Y_ = model.predict([X1, X2])\n",
    "                ytrue.extend(np.argmax(Y, axis=1).tolist())\n",
    "                ypred.extend(np.argmax(Y_, axis=1).tolist())\n",
    "        accuracy = accuracy_score(ytrue, ypred)\n",
    "        print(\"\\nAccuracy: {:.3f}\".format(accuracy))\n",
    "        print(\"\\nConfusion Matrix\")\n",
    "        print(confusion_matrix(ytrue, ypred))\n",
    "        print(\"\\nClassification Report\")\n",
    "        print(classification_report(ytrue, ypred))\n",
    "        return accuracy\n",
    "    \n",
    "def get_model_file(data_dir, vector_name, merge_mode, borf):\n",
    "        return os.path.join(data_dir, \"models\", \"{:s}-{:s}-{:s}.h5\"\n",
    "                                                .format(vector_name, merge_mode, borf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nelssalminen/anaconda3/envs/painter/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/35\n",
      "36075/36075 [==============================] - 735s 20ms/step - loss: 0.6379 - acc: 0.6245 - val_loss: 0.5880 - val_acc: 0.6909\n",
      "Epoch 2/35\n",
      "36075/36075 [==============================] - 742s 21ms/step - loss: 0.5524 - acc: 0.7102 - val_loss: 0.5202 - val_acc: 0.7529\n",
      "Epoch 3/35\n",
      "36075/36075 [==============================] - 742s 21ms/step - loss: 0.4911 - acc: 0.7568 - val_loss: 0.4686 - val_acc: 0.7911\n",
      "Epoch 4/35\n",
      "36075/36075 [==============================] - 744s 21ms/step - loss: 0.4462 - acc: 0.7881 - val_loss: 0.4322 - val_acc: 0.8167\n",
      "Epoch 5/35\n",
      "36075/36075 [==============================] - 742s 21ms/step - loss: 0.4121 - acc: 0.8104 - val_loss: 0.3972 - val_acc: 0.8334\n",
      "Epoch 6/35\n",
      "36075/36075 [==============================] - 740s 21ms/step - loss: 0.3860 - acc: 0.8268 - val_loss: 0.3816 - val_acc: 0.8451\n",
      "Epoch 7/35\n",
      "36075/36075 [==============================] - 744s 21ms/step - loss: 0.3655 - acc: 0.8391 - val_loss: 0.3606 - val_acc: 0.8545\n",
      "Epoch 8/35\n",
      "36075/36075 [==============================] - 742s 21ms/step - loss: 0.3489 - acc: 0.8488 - val_loss: 0.3497 - val_acc: 0.8614\n",
      "Epoch 9/35\n",
      "36075/36075 [==============================] - 742s 21ms/step - loss: 0.3351 - acc: 0.8566 - val_loss: 0.3428 - val_acc: 0.8654\n",
      "Epoch 10/35\n",
      "36075/36075 [==============================] - 741s 21ms/step - loss: 0.3240 - acc: 0.8627 - val_loss: 0.3341 - val_acc: 0.8702\n",
      "Epoch 11/35\n",
      "36075/36075 [==============================] - 736s 20ms/step - loss: 0.3141 - acc: 0.8679 - val_loss: 0.3246 - val_acc: 0.8740\n",
      "Epoch 12/35\n",
      "36075/36075 [==============================] - 727s 20ms/step - loss: 0.3057 - acc: 0.8723 - val_loss: 0.3159 - val_acc: 0.8766\n",
      "Epoch 13/35\n",
      "36075/36075 [==============================] - 725s 20ms/step - loss: 0.2982 - acc: 0.8762 - val_loss: 0.3133 - val_acc: 0.8801\n",
      "Epoch 14/35\n",
      "36075/36075 [==============================] - 725s 20ms/step - loss: 0.2915 - acc: 0.8796 - val_loss: 0.3128 - val_acc: 0.8796\n",
      "Epoch 15/35\n",
      "36075/36075 [==============================] - 725s 20ms/step - loss: 0.2853 - acc: 0.8825 - val_loss: 0.3016 - val_acc: 0.8840\n",
      "Epoch 16/35\n",
      "36075/36075 [==============================] - 724s 20ms/step - loss: 0.2798 - acc: 0.8853 - val_loss: 0.3002 - val_acc: 0.8848\n",
      "Epoch 17/35\n",
      "36075/36075 [==============================] - 724s 20ms/step - loss: 0.2746 - acc: 0.8878 - val_loss: 0.2948 - val_acc: 0.8874\n",
      "Epoch 18/35\n",
      "36075/36075 [==============================] - 724s 20ms/step - loss: 0.2698 - acc: 0.8900 - val_loss: 0.2957 - val_acc: 0.8878\n",
      "Epoch 19/35\n",
      "36075/36075 [==============================] - 724s 20ms/step - loss: 0.2653 - acc: 0.8921 - val_loss: 0.2907 - val_acc: 0.8890\n",
      "Epoch 20/35\n",
      "36075/36075 [==============================] - 723s 20ms/step - loss: 0.2611 - acc: 0.8942 - val_loss: 0.2880 - val_acc: 0.8909\n",
      "Epoch 21/35\n",
      "36075/36075 [==============================] - 723s 20ms/step - loss: 0.2571 - acc: 0.8960 - val_loss: 0.2848 - val_acc: 0.8913\n",
      "Epoch 22/35\n",
      "36075/36075 [==============================] - 724s 20ms/step - loss: 0.2535 - acc: 0.8976 - val_loss: 0.2810 - val_acc: 0.8929\n",
      "Epoch 23/35\n",
      "36075/36075 [==============================] - 723s 20ms/step - loss: 0.2497 - acc: 0.8994 - val_loss: 0.2831 - val_acc: 0.8930\n",
      "Epoch 24/35\n",
      "36075/36075 [==============================] - 724s 20ms/step - loss: 0.2465 - acc: 0.9009 - val_loss: 0.2792 - val_acc: 0.8937\n",
      "Epoch 25/35\n",
      "36075/36075 [==============================] - 723s 20ms/step - loss: 0.2433 - acc: 0.9022 - val_loss: 0.2782 - val_acc: 0.8947\n",
      "Epoch 26/35\n",
      "36075/36075 [==============================] - 723s 20ms/step - loss: 0.2401 - acc: 0.9037 - val_loss: 0.2743 - val_acc: 0.8963\n",
      "Epoch 27/35\n",
      "36075/36075 [==============================] - 723s 20ms/step - loss: 0.2372 - acc: 0.9049 - val_loss: 0.2731 - val_acc: 0.8965\n",
      "Epoch 28/35\n",
      "36075/36075 [==============================] - 723s 20ms/step - loss: 0.2345 - acc: 0.9063 - val_loss: 0.2680 - val_acc: 0.8979\n",
      "Epoch 29/35\n",
      "36075/36075 [==============================] - 727s 20ms/step - loss: 0.2317 - acc: 0.9075 - val_loss: 0.2670 - val_acc: 0.8985\n",
      "Epoch 30/35\n",
      "36075/36075 [==============================] - 725s 20ms/step - loss: 0.2291 - acc: 0.9086 - val_loss: 0.2679 - val_acc: 0.8969\n",
      "Epoch 31/35\n",
      "36075/36075 [==============================] - 726s 20ms/step - loss: 0.2265 - acc: 0.9098 - val_loss: 0.2646 - val_acc: 0.8994\n",
      "Epoch 32/35\n",
      "36075/36075 [==============================] - 725s 20ms/step - loss: 0.2236 - acc: 0.9110 - val_loss: 0.2617 - val_acc: 0.9003\n",
      "Epoch 33/35\n",
      "36075/36075 [==============================] - 723s 20ms/step - loss: 0.2215 - acc: 0.9120 - val_loss: 0.2602 - val_acc: 0.9002\n",
      "Epoch 34/35\n",
      "36075/36075 [==============================] - 723s 20ms/step - loss: 0.2196 - acc: 0.9128 - val_loss: 0.2658 - val_acc: 0.8997\n",
      "Epoch 35/35\n",
      "36075/36075 [==============================] - 724s 20ms/step - loss: 0.2170 - acc: 0.9140 - val_loss: 0.2620 - val_acc: 0.9010\n",
      "=== Evaluating model: inceptionv3-cat-final.h5 ===\n",
      "\n",
      "Accuracy: 0.901\n",
      "\n",
      "Confusion Matrix\n",
      "[[502350  74405]\n",
      " [ 39721 537828]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90    576755\n",
      "           1       0.88      0.93      0.90    577549\n",
      "\n",
      "   micro avg       0.90      0.90      0.90   1154304\n",
      "   macro avg       0.90      0.90      0.90   1154304\n",
      "weighted avg       0.90      0.90      0.90   1154304\n",
      "\n",
      "=== Evaluating model: inceptionv3-cat-best.h5 ===\n",
      "\n",
      "Accuracy: 0.900\n",
      "\n",
      "Confusion Matrix\n",
      "[[505649  71117]\n",
      " [ 44056 533482]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90    576766\n",
      "           1       0.88      0.92      0.90    577538\n",
      "\n",
      "   micro avg       0.90      0.90      0.90   1154304\n",
      "   macro avg       0.90      0.90      0.90   1154304\n",
      "weighted avg       0.90      0.90      0.90   1154304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_name = get_model_file(DATA_CONTAINER, \"inceptionv3\", \"cat\", \"best\")\n",
    "checkpoint = ModelCheckpoint(best_model_name, save_best_only=True)\n",
    "train_steps_per_epoch = len(train_triples) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(val_triples) // BATCH_SIZE\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps_per_epoch, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              validation_data=val_gen, validation_steps=val_steps_per_epoch,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "final_model_name = get_model_file(DATA_CONTAINER, \"inceptionv3\", \"cat\", \"final\")\n",
    "model.save(final_model_name)\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "final_accuracy = evaluate_model(final_model_name, test_gen)\n",
    "\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "best_accuracy = evaluate_model(best_model_name, test_gen)\n",
    "\n",
    "scores[0, 0] = best_accuracy if best_accuracy > final_accuracy else final_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
